{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test custom dataset script works\n",
    "\n",
    "env = simclr_pytorch_reefs_new\n",
    "\n",
    "The first code block is the full script from custom dataset, after this there are a few checks to inspect this acts as it should e.g train length should be ~54k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# for my transformations\n",
    "#import librosa\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, ClippingDistortion, Gain, SevenBandParametricEQ\n",
    "\n",
    "\n",
    "def resize_mel_spectrogram(mel_spec, desired_shape=(224, 224)):\n",
    "    # Convert the 2D Mel spectrogram to 4D tensor (batch, channels, height, width)\n",
    "    mel_spec_tensor = torch.tensor(mel_spec).unsqueeze(0).unsqueeze(0)\n",
    "    # Resize\n",
    "    resized_mel_spec = F.interpolate(mel_spec_tensor, size=desired_shape, mode='bilinear', align_corners=False)\n",
    "    return resized_mel_spec.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "# augmentation\n",
    "augment_raw_audio = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.0001, max_amplitude=0.0005, p=1), # good\n",
    "        PitchShift(min_semitones=-2, max_semitones=12, p=0.5), #set values so it doesnt shift too low, rmeoving bomb signal\n",
    "        TimeStretch(p = 0.5), # defaults are fine\n",
    "        ClippingDistortion(0, 5, p = 0.5), # tested params to make sure its good\n",
    "        Gain(-10, 5, p = 0.5), # defaults are fine\n",
    "        # throws an error, so i commented it out\n",
    "        #SevenBandParametricEQ(-12, 12, p = 0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Modify the load_audio_and_get_mel_spectrogram function:\n",
    "def mel_spectrogram_func(filename, augment, sr=8000, n_mels=128, n_fft=1024, hop_length=64, win_length=512):\n",
    "    y, _ = librosa.load(filename, sr=sr)\n",
    "\n",
    "    # apply transformations for train data if True, not for test data if False\n",
    "    if augment ==True:\n",
    "        # pass to augmentation function first then pass to mel spec below\n",
    "        audio_signal = augment_raw_audio(y, sr)\n",
    "    else:\n",
    "        # skip right to mel spec below\n",
    "        audio_signal = y\n",
    "\n",
    "    # compute the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_signal, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "    mel_spectrogram_resized = resize_mel_spectrogram(mel_spectrogram)\n",
    "    return mel_spectrogram_resized\n",
    "\n",
    "\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, cfg, split, transform):\n",
    "        '''\n",
    "            Constructor. Here, we collect and index the dataset inputs and labels.\n",
    "        '''\n",
    "        #if split == 'unlabeled':\n",
    "         #   print('This will not work unless you change the getitem function to have no labels for the unlabeled set') \n",
    "        self.data_root = cfg['data_path']\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "#\n",
    "\n",
    "        # index data from JSON file\n",
    "        self.data = []\n",
    "        with open(cfg['json_path'], 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "            for sublist in json_data.values():\n",
    "                for entry in sublist:\n",
    "                    #print(entry)\n",
    "\n",
    "                    if entry[\"data_type\"] == split:\n",
    "                        path = entry[\"file_name\"]\n",
    "                        label = entry[\"class\"]\n",
    "                        self.data.append([path, label]) ###chNGED TO LIST \n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "            Returns the length of the dataset.\n",
    "        '''\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "            Returns a single data point at given idx.\n",
    "            Here's where we actually load the audio and get the Mel spectrogram.\n",
    "        '''\n",
    "        #print(f'shape of id: {type(idx)}')\n",
    "        #print(idx)\n",
    "        audio_path, label = self.data[idx]\n",
    "\n",
    "        # load audio and get Mel spectrogram\n",
    "        if self.transform == True:\n",
    "            mel_spectrogram = mel_spectrogram_func(filename = os.path.join(self.data_root, audio_path), augment = True)\n",
    "        elif self.transform == False:\n",
    "            mel_spectrogram = mel_spectrogram_func(filename = os.path.join(self.data_root, audio_path), augment = False)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"The 'transform' parameter must be either True or False.\")\n",
    "\n",
    "            \n",
    "        \n",
    "        # make 3 dimensions, so shape goes from [x, y] to [3, x, y]\n",
    "        mel_spectrogram_tensor = torch.tensor(mel_spectrogram).unsqueeze(0).repeat(3, 1, 1).float()\n",
    "        \n",
    "        # the old transform call, its now ditched\n",
    "        #if self.transform:\n",
    "         #   mel_spectrogram_tensor = self.transform(mel_spectrogram_tensor)\n",
    "\n",
    "        # return the objects, label is commented out for now\n",
    "        return mel_spectrogram_tensor#, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line will get passed in the \n",
    "cfg = {'data_path': '/mnt/ssd-cluster/ben/data/full_dataset/', #############################\n",
    "    'json_path': '/home/ben/reef-audio-representation-learning/data/dataset.json'}\n",
    "\n",
    "train_dataset = CTDataset(cfg, split='test_data', transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24609"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CTDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix this to view specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataset\u001b[39m.\u001b[39mbypass_augmentations \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39m# change to True to prevent augmentations\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tensors \u001b[39m=\u001b[39m [train_dataset[i]\u001b[39m.\u001b[39mdata \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m sample_labels \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(train_dataset[i]\u001b[39m.\u001b[39mlabels[train_dataset[i]\u001b[39m.\u001b[39mlabels\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mindex) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[1;32m      8\u001b[0m _ \u001b[39m=\u001b[39m show_tensor_grid(tensors,\u001b[39m3\u001b[39m,labels\u001b[39m=\u001b[39msample_labels)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataset\u001b[39m.\u001b[39mbypass_augmentations \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39m# change to True to prevent augmentations\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tensors \u001b[39m=\u001b[39m [train_dataset[i]\u001b[39m.\u001b[39mdata \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m sample_labels \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(train_dataset[i]\u001b[39m.\u001b[39;49mlabels[train_dataset[i]\u001b[39m.\u001b[39mlabels\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mindex) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[1;32m      8\u001b[0m _ \u001b[39m=\u001b[39m show_tensor_grid(tensors,\u001b[39m3\u001b[39m,labels\u001b[39m=\u001b[39msample_labels)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "# sample.data returns the tensor\n",
    "# sample.label returns the label (all 1)\n",
    "\n",
    "train_dataset.bypass_augmentations = False # change to True to prevent augmentations\n",
    "tensors = [train_dataset[i].data for i in range(3)]\n",
    "sample_labels = [list(train_dataset[i].labels[train_dataset[i].labels>0].index) for i in range(3)]\n",
    "\n",
    "_ = show_tensor_grid(tensors,3,labels=sample_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr_pytorch_reefs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
