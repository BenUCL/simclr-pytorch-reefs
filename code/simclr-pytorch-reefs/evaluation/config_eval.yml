# Here's where you define experiment-specific hyperparameters.
# You can also create lists and group parameters together into nested sub-parts.
# In Python, this is all read as a dict.
test_dataset: test_australia
train_percent: 0.2 # change for dataset


# environment/computational parameters
seed: 0       # random number generator seed (long integer value)
device: cuda
num_workers: 4

# dataset parameters
data_root: /mnt/ssd-cluster/ben/data/full_dataset/
data_path: /mnt/ssd-cluster/ben/data/full_dataset/
json_path: /home/ben/reef-audio-representation-learning/data/dataset.json
num_classes: 51
train_label_file: [/root/10_percent_train_with_unknown.csv]
#train_label_file: [/root/10_percent_train_with_unknown.csv, /root/10p_predictions_on_unlabeled_thresh_0.1_simclr.csv]
val_label_file: /root/5_percent_val_with_unknown.csv
test_label_file: /root/10_percent_test_with_unknown.csv
unlabeled_file: /root/75_percent_unlabeled_with_unknown.csv
#inference_weights: /root/ct_classifier/model_states_paws/10p_paws_200.pt
#inference_weights: /root/ct_classifier/model_states_simclr/200.pt
inference_weights: /root/ct_classifier/model_states/resnet50_10p_200epochs.pt

#inference_weights: /root/ct_classifier/model_states_simclr/10p_plus_psuedo_label_0.1_200.pt
#inference_weights: /root/ct_classifier/model_states_simclr_1024/10p_simclr_200.pt

# if starting_weights: None, it defaults to imagenet
#starting_weights: None
#starting_weights: /root/ct_classifier/model_states_simclr/200.pt
#starting_weights: /root/simclr-pytorch/logs/exman-train.py/runs/000022/checkpoint-12100.pth.tar
#starting_weights: /root/simclr-pytorch/logs/exman-train.py/runs/000052/checkpoint-3000.pth.tar

# comment this out if using imagenet weights
starting_weights: /home/ben/reef-audio-representation-learning/code/simclr-pytorch-reefs/logs/exman-train.py/runs/000001/checkpoint-5100.pth.tar

finetune: True # this will only train the last head if true i.e regression
# training hyperparameters
image_size: [224, 224]
num_epochs: 3
batch_size: 16
learning_rate: 0.001
weight_decay: 0.001